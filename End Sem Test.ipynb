{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(s1 , s2):\n",
    "    m = []\n",
    "    for i in range(len(s1)+1):\n",
    "        l = []\n",
    "        for j in range(len(s2)+1):\n",
    "            l.append([0])\n",
    "        m.append(l)\n",
    "    \n",
    "    for i in range(len(s1) + 1):\n",
    "        m[i][0] = i\n",
    "        \n",
    "    for j in range(len(s2) + 1):\n",
    "        m[0][j] = j\n",
    "        \n",
    "    for i in range(1,len(s1) + 1):\n",
    "        for j in range(1,len(s2) + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                m[i][j] = min(min(m[i-1][j-1], m[i-1][j] + 1), m[i][j-1] + 1)\n",
    "            else:\n",
    "                m[i][j] = min(min(m[i-1][j-1] + 1, m[i-1][j] + 1), m[i][j-1] + 1)\n",
    "    \n",
    "    return m[len(s1)][len(s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtoken = \"gafffe\"\n",
    "compares = [\"half\", \"puff\", \"gaffe\", \"cafe\"]\n",
    "temp = []\n",
    "for i in compares :\n",
    "    temp.append((i,edit_distance(qtoken,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1 = sorted(temp, key= lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gaffe', 1), ('cafe', 3), ('half', 4), ('puff', 4)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cranfield = open(\"C:\\\\Users\\\\acer\\\\Desktop\\\\lamaj\\\\Cranfield\\\\cran.all.1400\", \"r\", encoding = \"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cranfield = re.sub(r\"\\n\",\" \", cranfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"\\.W.+?\\.I\")\n",
    "body = re.findall(pattern, cranfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [i[3:-4] for i in body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.append(\"\"\"the buckling shear stress of simply-supported infinitely long plates with transverse stiffeners . this report is an extension of previous theoretical investigations of the elastic buckling in shear of flat plates reinforced by transverse stiffeners . the plates are treated as infinitely long and simply-supported along the long sides . stiffeners are spaced at regular intervals, dividing the plate into a number of panels of uniform size . the effect ob bending and torsional stiffnesses of the stiffener upon the buckling shear stress is calculated for the complete range of stiffnesses, for panels with ratios of width to stiffener spacing of graphical forms\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('C:\\\\Users\\\\acer\\\\Desktop\\\\lamaj\\\\stopwords.txt').read()\n",
    "stopwords = stopwords.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lower = False, limit = 3):\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    spept = re.compile(r\"[^0-9a-zA-Z\\-\\']\")\n",
    "    text = re.sub(spept, \" \", text)\n",
    "    pt = re.compile(r\"\\w*[-|']{0,1}\\w*\")\n",
    "    tokens = list(filter(pt.match, text.split(\" \")))\n",
    "    if lower:\n",
    "        bt_tokens = [tk.lower() for tk in tokens if len(tk ) > limit and tk not in stopwords]\n",
    "    else:\n",
    "        bt_tokens = [tk for tk in tokens if len(tk ) > limit and tk not in stopwords]\n",
    "    return bt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 0\n",
    "vocab = []\n",
    "doc_tokens = []\n",
    "for text in docs:\n",
    "    token_list = tokenize(text,True, 3)\n",
    "    doc_token = Counter(token_list)\n",
    "    doc_tokens.append(doc_token)\n",
    "    vocab.extend(doc_token.keys())\n",
    "    doc_id = doc_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8518"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(vocab, doc_tokens):\n",
    "    tf_mat = []\n",
    "    for cterm in vocab:\n",
    "        tfrow = []\n",
    "        for i in range(len(doc_tokens)):\n",
    "            if doc_tokens[i].get(cterm) != None:\n",
    "                tfrow.append(doc_tokens[i][cterm])\n",
    "            else:\n",
    "                tfrow.append(0)\n",
    "        tf_mat.append(tfrow)\n",
    "\n",
    "    return np.array(tf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InverseDocFreq(vocab, doc_tokens):\n",
    "    idf = []\n",
    "    for cterm in vocab:\n",
    "        count = 0\n",
    "        for i in range(len(doc_tokens)):\n",
    "            if doc_tokens[i].get(cterm) != None:\n",
    "                count = count + 1\n",
    "        idf.append(math.log(len(doc_tokens)/count))\n",
    "\n",
    "    return np.array(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfvector(vocab, doc_tokens):\n",
    "    \n",
    "    tf_mat = term_frequency(vocab, doc_tokens)\n",
    "    idf = InverseDocFreq(vocab, doc_tokens)\n",
    "    tfIdf = []\n",
    "    for i in range(tf_mat.shape[0]):\n",
    "        tfIdf.append(tf_mat[i,:].T*idf[i].T)\n",
    "\n",
    "    return np.array(tfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(qvector, tfIdf):\n",
    "    cos = {}\n",
    "    for i in range(tfIdf.shape[1]):\n",
    "        dot = (qvector.T*tfIdf[:,i].T).sum()\n",
    "        cos[i] = dot/(tfIdf.shape[0])\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryCosineCalc(query, tfIdf):\n",
    "    qtoken_list = tokenize(query,True,3)\n",
    "    qvector = []\n",
    "    for cterm in vocab:\n",
    "        if cterm in qtoken_list:\n",
    "            qvector.append(1)\n",
    "        else:\n",
    "            qvector.append(0)\n",
    "\n",
    "    qvector = np.array(qvector)\n",
    "    cos = cosine(qvector, tfIdf)\n",
    "    ans2 = sorted([(i+1,v) for i,v in cos.items()], key = lambda x: x[1], reverse = True)\n",
    "    print(\"Docs\\t\\tCosine : \\n\")\n",
    "    for i in ans2[:4]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdf = tfidfvector(vocab, doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query : what problems of heat conduction in composite slabs have been solved so far\n",
      "Docs\t\tCosine : \n",
      "\n",
      "(144, 0.004675759368948767)\n",
      "(542, 0.0035647364577836727)\n",
      "(5, 0.0029318280320715607)\n",
      "(707, 0.0027545549477447128)\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter Query : \")\n",
    "queryCosineCalc(query, tfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query : what is the basic mechanism of the transonic aileron buzz\n",
      "Docs\t\tCosine : \n",
      "\n",
      "(496, 0.004617761486810521)\n",
      "(199, 0.004244365087751186)\n",
      "(1268, 0.0033079903539734736)\n",
      "(903, 0.003023467465792699)\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter Query : \")\n",
    "queryCosineCalc(query, tfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
